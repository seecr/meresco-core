Changeset created on 2009-10-14 16:29:54 +0200 (Wed, 14 Oct 2009) by Seek You Too

Description: Improved Reindex component.

    Reindex was originally developed for UvT (Tilburg University), this change melt the 2 original components together and added support for reindexing in batches.

Baseline version: meresco-core/tags/version_2.22.6

diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_original/merescocore/components/__init__.py version_0/merescocore/components/__init__.py
--- version_original/merescocore/components/__init__.py	2010-01-21 19:26:16.000000000 +0100
+++ version_0/merescocore/components/__init__.py	2010-01-21 19:19:48.000000000 +0100
@@ -47,7 +47,7 @@
 from xpath2field import XPath2Field
 from rewritepartname import RewritePartname
 from filtermessages import FilterMessages
-from reindex import Reindex, ReindexConsole
+from reindex import Reindex
 from parsecql import ParseCQL
 from cqlconversion import CQLConversion, CqlSearchClauseModification, CqlSearchClauseConversion
 from renamecqlindex import RenameCqlIndex
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_original/merescocore/components/reindex.py version_0/merescocore/components/reindex.py
--- version_original/merescocore/components/reindex.py	2010-01-21 19:26:16.000000000 +0100
+++ version_0/merescocore/components/reindex.py	2010-01-21 19:19:48.000000000 +0100
@@ -1,3 +1,4 @@
+# -*- coding: utf-8 -*-
 ## begin license ##
 #
 #    Meresco Core is an open-source library containing components to build
@@ -26,33 +27,93 @@
 #
 ## end license ##
 
+from __future__ import with_statement
+
 from merescocore.framework import Observable
 from lxml.etree import parse
 from StringIO import StringIO
+from os.path import isdir, join
+from os import makedirs, listdir, remove, rmdir
 
 EMPTYDOC = parse(StringIO('<empty/>'))
 
 class Reindex(Observable):
 
-    def __init__(self, partName):
+    def __init__(self, partName, filelistPath=''):
         Observable.__init__(self)
         self._partName = partName
-
-    def reindex(self, identifierPrefix=''):
-        for identifier in self.any.listIdentifiers(self._partName, identifierPrefix=identifierPrefix):
-            try:
-                self.do.addDocumentPart(identifier=identifier, name='ignoredName', lxmlNode=EMPTYDOC)
-            except:
-                print 'ERROR', identifier
-                raise
-            yield identifier
-
-class ReindexConsole(Observable):
+        self._filelistPath = filelistPath
+        if not isdir(self._filelistPath):
+            makedirs(self._filelistPath)
 
     def handleRequest(self, *args, **kwargs):
         arguments = kwargs.get('arguments', {})
-        identifierPrefix = arguments.get('identifierPrefix', [''])[0]
+        try:
+            session = arguments.get('session', [''])[0]
+        except IndexError:
+            session = ''
+
+        batchSize = int(arguments.get('batchsize', [200])[0])
         yield "HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n"
-        for id in self.all.reindex(identifierPrefix=identifierPrefix):
-            yield id + "\n"
-        yield "done"
+        if session == '':
+            yield "!error: session missing"
+            return
+        if batchSize > 2000  or batchSize <= 0:
+            yield "!error: invalid batchsize"
+            return
+
+        sessionDirectory = join(self._filelistPath, session)
+        if not isdir(sessionDirectory):
+            results = self._createBatches(sessionDirectory, batchSize)
+        else:
+            results = self._processBatches(sessionDirectory)
+
+        for result in results:
+            yield result
+
+
+    def _createBatches(self, sessionDirectory, batchSize):
+        currentBatch = 0
+        batch = []
+        identifiersFound = False
+
+        for identifier in self.any.listIdentifiers(self._partName):
+            batch.append(identifier)
+            if len(batch) == batchSize:
+                identifiersFound = self._writeBatch(sessionDirectory, currentBatch, batch)
+                yield "#"
+                currentBatch += 1
+                batch = []
+        additionalBatch = 0
+        if batch != []:
+            identifiersFound = self._writeBatch(sessionDirectory, currentBatch, batch)
+            additionalBatch = 1
+            yield "#"
+        if not identifiersFound:
+            yield "!error: no identifiers"
+            return
+        yield '\n=batches: %d' % (currentBatch + additionalBatch)
+
+    def _writeBatch(self, sessionDirectory, number, batch):
+        if not isdir(sessionDirectory):
+            makedirs(sessionDirectory)
+
+        with open(join(sessionDirectory, 'batch_%0.15d' % number), 'w') as fd:
+            fd.write('\n'.join(batch))
+        return True
+
+    def _processBatches(self, sessionDirectory):
+        batchFile = join(sessionDirectory, listdir(sessionDirectory)[0])
+
+        for identifier in (identifier.strip() for identifier in open(batchFile).readlines()):
+            try:
+                self.do.addDocumentPart(identifier=identifier, name='ignoredName', lxmlNode=EMPTYDOC)
+            except Exception, e:
+                yield '\n!error processing "%s": %s' % (identifier, str(e))
+                return
+            yield "+%s\n" % identifier
+
+        remove(batchFile)
+        yield "=batches left: %d" % len(listdir(sessionDirectory))
+        if len(listdir(sessionDirectory)) == 0:
+            rmdir(sessionDirectory)
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_original/test/alltests.py version_0/test/alltests.py
--- version_original/test/alltests.py	2010-01-21 19:26:15.000000000 +0100
+++ version_0/test/alltests.py	2010-01-21 19:19:47.000000000 +0100
@@ -59,7 +59,6 @@
 from xml2fieldstest import Xml2FieldsTest
 from xpath2fieldtest import XPath2FieldTest
 from reindextest import ReindexTest
-from reindexconsoletest import ReindexConsoleTest
 
 from framework.helixtest import HelixTest
 from framework.generatorutilstest import GeneratorUtilsTest
Only in version_original/test: reindexconsoletest.py
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_original/test/reindextest.py version_0/test/reindextest.py
--- version_original/test/reindextest.py	2010-01-21 19:26:15.000000000 +0100
+++ version_0/test/reindextest.py	2010-01-21 19:19:47.000000000 +0100
@@ -1,4 +1,5 @@
 #!/usr/bin/env python2.5
+# -*- coding: utf-8 -*-
 ## begin license ##
 #
 #    Meresco Core is an open-source library containing components to build
@@ -29,12 +30,17 @@
 
 from cq2utils import CQ2TestCase, CallTrace
 from merescocore.components import StorageComponent, Reindex, FilterMessages
-from merescocore.framework import be
+from merescocore.framework import be, Observable
+
+from os.path import join, isdir
+from os import listdir
 
 class ReindexTest(CQ2TestCase):
+    def _path(self, subdir):
+        return join(self.tempdir, subdir)
 
     def setupStorage(self, records):
-        storage = StorageComponent(self.tempdir)
+        storage = StorageComponent(self._path('storage'))
         for record in records:
             storage.add(*record)
         return storage
@@ -42,7 +48,7 @@
     def setupDna(self, storage):
         observer = CallTrace('observer')
         reindex = be(
-            (Reindex('part'),
+            (Reindex(filelistPath=self._path('reindex'), partName='part'),
                 (FilterMessages(allowed=['listIdentifiers']),
                     (storage, ),
                 ),
@@ -51,37 +57,130 @@
         )
         return reindex, observer
 
-    def testEnumerateStorage(self):
+    def testArguments(self):
+        reindex, observer = self.setupDna(CallTrace('Storage'))
+        def assertError(message, arguments):
+            result = list(reindex.handleRequest(arguments=arguments))
+            self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', message], result)
+        assertError('!error: session missing', {})
+        assertError('!error: session missing', {'session': []})
+
+        assertError('!error: invalid batchsize', {'session': ['test'], 'batchsize': ['-1']})
+        assertError('!error: invalid batchsize', {'session': ['test'], 'batchsize': ['0']})
+        assertError('!error: invalid batchsize', {'session': ['test'], 'batchsize': ['2001']})
+
+    def testWithEmptyStorage(self):
+        reindex, observer = self.setupDna(CallTrace('Storage', returnValues={'listIdentifiers': []}))
+        directory = join(self._path('reindex'), 'testcase')
+        self.assertFalse(isdir(directory))
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        self.assertFalse(isdir(directory))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', "!error: no identifiers"], result)
+
+    def testCreateIdentifierFiles(self):
+        storage = self.setupStorage([
+            ('id:1', 'part', 'data1'),
+            ('id:2', 'part', 'data2'),
+            ('id:3', 'part', 'data3'),
+        ])
+        reindex, observer = self.setupDna(storage)
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        directory = join(self._path('reindex'), 'testcase')
+        self.assertTrue(isdir(directory))
+        files = listdir(directory)
+        self.assertEquals(1, len(files))
+        identifiers = list(identifier for identifier in open(join(directory, files[0])).read().split('\n') if identifier != '')
+        self.assertEquals(['id:1', 'id:2', 'id:3'], identifiers)
+
+    def testCreateIdentifierFilesInBatches(self):
         storage = self.setupStorage([
-            ('identifier:A', 'part', 'data1'),
-            ('identifier:B', 'part', 'data2'),
-            ('identifier:C', 'part', 'data3'),
+            ('id:1', 'part', 'data1'),
+            ('id:2', 'part', 'data2'),
+            ('id:3', 'part', 'data3'),
         ])
-        self.assertEquals(set(['identifier:B', 'identifier:C', 'identifier:A']), set(storage.listIdentifiers()))
+        reindex, observer = self.setupDna(storage)
+        result = list(reindex.handleRequest(arguments={'session': ['testcase'], 'batchsize': ['1']}))
+        directory = join(self._path('reindex'), 'testcase')
+        self.assertTrue(isdir(directory))
+        files = listdir(directory)
+        self.assertEquals(3, len(files))
 
+    def testCreateIdentifierFilesYieldsOutput(self):
+        storage = self.setupStorage([
+            ('id:1', 'part', 'data1'),
+            ('id:2', 'part', 'data2'),
+            ('id:3', 'part', 'data3'),
+        ])
         reindex, observer = self.setupDna(storage)
-        result = list(reindex.reindex())
-        self.assertEquals(3, len(observer.calledMethods))
-        methods = sorted(map(str, observer.calledMethods))
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
 
-        self.assertEquals("addDocumentPart(identifier='identifier:A', name='ignoredName', lxmlNode=<etree._ElementTree>)", methods[0])
-        self.assertEquals("addDocumentPart(identifier='identifier:B', name='ignoredName', lxmlNode=<etree._ElementTree>)", methods[1])
-        self.assertEquals("addDocumentPart(identifier='identifier:C', name='ignoredName', lxmlNode=<etree._ElementTree>)", methods[2])
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '#', '\n=batches: 1'], result)
 
-    def testSelectIdentifiers(self):
+    def testProcessCreatedBatches(self):
         storage = self.setupStorage([
-            ('identifier:1A', 'part', 'data1'),
-            ('identifier:1B', 'part', 'data2'),
-            ('identifier:2C', 'part', 'data3'),
+            ('id:1', 'part', 'data1'),
+            ('id:2', 'part', 'data2'),
+            ('id:3', 'part', 'data3'),
         ])
         reindex, observer = self.setupDna(storage)
-        result = list(reindex.reindex(identifierPrefix="identifier:1"))
-        self.assertEquals(2, len(observer.calledMethods))
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
 
-        observer.calledMethods = []
-        result = list(reindex.reindex(identifierPrefix="identifier:2"))
-        self.assertEquals(1, len(observer.calledMethods))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '#', '\n=batches: 1'], result)
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '+id:1\n', '+id:2\n', '+id:3\n', '=batches left: 0'], result)
+
+        methods = [str(m) for m in observer.calledMethods]
+        self.assertEquals(3, len(methods))
+        self.assertEquals("addDocumentPart(identifier='id:1', name='ignoredName', lxmlNode=<etree._ElementTree>)", methods[0])
+        self.assertEquals("addDocumentPart(identifier='id:2', name='ignoredName', lxmlNode=<etree._ElementTree>)", methods[1])
+        self.assertEquals("addDocumentPart(identifier='id:3', name='ignoredName', lxmlNode=<etree._ElementTree>)", methods[2])
 
-        observer.calledMethods = []
-        result = list(reindex.reindex(identifierPrefix="identifier:"))
-        self.assertEquals(3, len(observer.calledMethods))
+    def testRemoveFilesAndDirectoryAfterProcess(self):
+        storage = self.setupStorage([
+            ('id:1', 'part', 'data1'),
+            ('id:2', 'part', 'data2'),
+            ('id:3', 'part', 'data3'),
+        ])
+        reindex, observer = self.setupDna(storage)
+        directory = join(self._path('reindex'), 'testcase')
+
+        result = list(reindex.handleRequest(arguments={'session': ['testcase'], 'batchsize': ['1']}))
+        self.assertEquals(3, len(listdir(directory)))
+        self.assertTrue(isdir(directory))
+
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        self.assertEquals(2, len(listdir(directory)))
+        self.assertTrue(isdir(directory))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '+id:1\n', '=batches left: 2'], result)
+
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        self.assertEquals(1, len(listdir(directory)))
+        self.assertTrue(isdir(directory))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '+id:2\n', '=batches left: 1'], result)
+
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        self.assertFalse(isdir(directory))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '+id:3\n','=batches left: 0'], result)
+
+    def testProcessGivesError(self):
+        storage = self.setupStorage([
+            ('id:1', 'part', 'data1'),
+            ('id:2', 'part', 'data2'),
+            ('id:3', 'part', 'data3'),
+        ])
+        reindex, observer = self.setupDna(storage)
+        observer.exceptions['addDocumentPart'] = Exception('An Error Occured')
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '#', '\n=batches: 1'], result)
+        result = list(reindex.handleRequest(arguments={'session': ['testcase']}))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '\n!error processing "id:1": An Error Occured'], result)
+
+    def testNotOffByOneIfNoRemainder(self):
+        records = [('id:%d' % i, 'part', 'data%d' % i) for i in range(80)]
+        storage = self.setupStorage(records)
+        reindex, observer = self.setupDna(storage)
+        directory = join(self._path('reindex'), 'testcase')
+        result = list(reindex.handleRequest(arguments={'session': ['testcase'], 'batchsize': ['5']}))
+        self.assertEquals(16, len(listdir(directory)))
+        self.assertEquals(['HTTP/1.0 200 OK\r\nContent-Type: plain/text\r\n\r\n', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', '\n=batches: 16'], result)
